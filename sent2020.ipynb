{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yearly(y):\n",
    "    PATH = 'Fox_NY_' + str(y) + '/'\n",
    "    nb = 1\n",
    "    df2 = []\n",
    "    dirs = glob.glob(os.path.join(PATH, \"*.pkl\"))\n",
    "\n",
    "    for files in dirs:\n",
    "        df1 = pd.read_pickle(PATH + str(nb)+ '_' + str(y) + '_' + 'FoxNYtimes.pkl')\n",
    "        df2.append(df1)\n",
    "        nb += 1\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2020]\n",
    "df_foxNy3 = pd.DataFrame()\n",
    "\n",
    "for y in years:\n",
    "  df_foxNy3 = df_foxNy3.append(pd.concat(read_yearly(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\François\n",
      "[nltk_data]     CHARROIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\François\n",
      "[nltk_data]     CHARROIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\François\n",
      "[nltk_data]     CHARROIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "from collections import namedtuple\n",
    "import text2emotion as te\n",
    "df_fox3 = df_foxNy3[df_foxNy3['urls'].str.contains('foxnews')]\n",
    "df_ny3 = df_foxNy3[df_foxNy3['urls'].str.contains('nytimes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fon_text2 (df):\n",
    "    Desc = namedtuple(\"Desc\", [\"fear\", \"happy\", \"angry\",\"surprise\",\"sad\",\"length\"])\n",
    "    df_quotes=df['quotation']\n",
    "    dfsize=len(df_quotes)\n",
    "    fear=0\n",
    "    happy=0\n",
    "    angry=0\n",
    "    surprise=0\n",
    "    sad=0\n",
    "    average_fear=0\n",
    "    average_happy=0\n",
    "    average_angry=0\n",
    "    average_surprise=0\n",
    "    average_sad=0\n",
    "\n",
    "    for quotation in df_quotes:\n",
    "        di=te.get_emotion(quotation)\n",
    "        fear+=di.get('Fear')\n",
    "        happy+=di.get('Happy')\n",
    "        angry+=di.get('Angry')\n",
    "        surprise+=di.get('Surprise')\n",
    "        sad+=di.get('Sad')\n",
    "    average_fear=fear/dfsize\n",
    "    average_happy=happy/dfsize\n",
    "    average_angry=angry/dfsize\n",
    "    average_surprise=surprise/dfsize\n",
    "    average_sad=sad/dfsize\n",
    "\n",
    "    print(\"fear{}, happy{}, angry{}, surprise{}, sad{}\".format(average_fear,average_happy,\n",
    "                                                               average_angry,average_surprise,average_sad))\n",
    "    return (Desc(fear,happy,angry,surprise,sad,dfsize,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fon_nltk (df):\n",
    "    Desc = namedtuple(\"Desc\", [\"pos\", \"neg\", \"tot\"])\n",
    "    quotes=df['quotation']\n",
    "    length= len(df)\n",
    "    pos=0\n",
    "    neg=0\n",
    "    average_pos=0\n",
    "    average_neg=0\n",
    "    for quotation in quotes:\n",
    "        result=sia.polarity_scores(quotation)\n",
    "        pos+=result[\"pos\"]\n",
    "        neg+=result[\"neg\"]\n",
    "    average_pos=pos/length\n",
    "    average_neg=neg/length\n",
    "    print('Mean of positif and negatif feelings found respectively are:', average_pos,average_neg)\n",
    "    return (Desc(pos, neg, length,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of positif and negatif feelings found respectively are: 0.10547141987123755 0.07730176613885521\n",
      "4849.154000000018 3554.0260000000076 45976\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "length=0\n",
    "pos,neg,length=fon_nltk(df_ny3)\n",
    "print(pos,neg,length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of positif and negatif feelings found respectively are: 0.11349214548268631 0.07977823563551907\n",
      "5866.409000000055 4123.736999999981 51690\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "length=0\n",
    "pos,neg,length=fon_nltk(df_fox3)\n",
    "print(pos,neg,length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear0.3368202975465449, happy0.09344636331998993, angry0.046844658082477536, surprise0.17906385940490221, sad0.19569558030276257\n",
      "15485.649999999949 4296.289999999857 2153.7299999999873 8232.639999999785 8997.299999999812 45976\n"
     ]
    }
   ],
   "source": [
    "fear=0\n",
    "happy=0\n",
    "angry=0\n",
    "surprise=0\n",
    "sad=0\n",
    "tot=0\n",
    "\n",
    "fear,happy,angry,surprise,sad,tot = fon_text2(df_ny3)\n",
    "print(fear,happy,angry,surprise,sad,tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear0.3480504933256054, happy0.1047626233313944, angry0.04698432965757303, surprise0.20168833430063893, sad0.20202360224414842\n",
      "17990.73000000054 5415.179999999777 2428.61999999995 10425.270000000026 10442.600000000031 51690\n"
     ]
    }
   ],
   "source": [
    "fear=0\n",
    "happy=0\n",
    "angry=0\n",
    "surprise=0\n",
    "sad=0\n",
    "tot=0\n",
    "\n",
    "fear,happy,angry,surprise,sad,tot = fon_text2(df_fox3)\n",
    "print(fear,happy,angry,surprise,sad,tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
